{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> **Tokenisation** </font> is defined as the process of breaking up a string into tokens. \n",
    "Tokens are the basic building blocks of a sentence. In English, tokens are words, punctuation, and numbers.\n",
    "\n",
    "For German tokenisation, we need to consider the following:\n",
    "- German has compound words, e.g. \"Krankenhaus\" (hospital) is made up of \"Kranken\" (sick) and \"Haus\" (house).\n",
    "- German has umlauts, e.g. \"ä\", \"ö\", \"ü\", \"ß\".\n",
    "- German has a different punctuation system, e.g. \"„\", \"“\", \"–\", \"…\", \"»\", \"«\".\n",
    "\n",
    "Let us focus first on English tokenization. That in itself is not trivial. \n",
    "Web based text can be:\n",
    "1. formal (e.g. news articles when we want to build a news summarizer) \n",
    "2. informal (e.g. twitter when we want to build a sentiment analyzer) Interesting things happen when we deal with modern vocabulary found in informal texts like twitter.\n",
    "\n",
    "Especially when we work with web based texts, we need to consider the following (with examples):\n",
    "- HTML tags (e.g. \\<br\\>)\n",
    "- URLs (http://www.example.com)\n",
    "- Emoticons (:-))\n",
    "- Abbreviations (e.g. \"Mr.\", \"Mrs.\", \"Dr.\", \"Prof.\")\n",
    "- Punctuation (e.g. \"!\", \"?\", \".\", \",\", \";\", \":\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\")\n",
    "- Numbers (e.g. \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\")\n",
    "- Contractions (didn't = did not, capp'n=capping, )\n",
    "- Currency symbols (e.g. \"$\", \"€\", \"£\", \"¥\")\n",
    "- Hyphenated words (e.g. \"self-driving\")\n",
    "- Words with apostrophes (e.g. \"it's\")\n",
    "- Words with underscores (e.g. \"@this_is_a_twitter_handle\")\n",
    "- Special characters (e.g. \"@\", \"#\", \"%\", \"&\", \"*\", \"+\", \"=\", \"~\", \"_\")\n",
    "- Non-ASCII characters (e.g. \"é\", \"ñ\", \"ç\", \"ß\")\n",
    "- Words with periods (e.g. \"U.S.\", \"U.N.\", \"U.d.S.\", \"L.S.T.\")\n",
    "and much more... \n",
    "\n",
    "Today we will cover a subset of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
